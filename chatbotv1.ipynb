{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a4cfc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import gradio as gr\n",
    "import json\n",
    "from getpass import getpass\n",
    "from huggingface_hub import login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0be131",
   "metadata": {},
   "outputs": [],
   "source": [
    "login(token=\"change this into your token \") #change the token into your hf token \n",
    "API_URL = \"https://api-inference.huggingface.co/models/mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "headers = {\"Authorization\": f\"Bearer {'change this into your token '}\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20e6552b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_model_status(url):\n",
    "    try:\n",
    "        response = requests.post(url, headers=headers, json={\"inputs\": \"test\"})\n",
    "        return \"Model is ready\" if response.status_code == 200 else f\"Status: {response.status_code}\"\n",
    "    except Exception as e:\n",
    "        return f\"Connection error: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0cc46d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(task, user_input):\n",
    "    \"\"\"Generate responses using different prompt patterns\"\"\"\n",
    "    try:\n",
    "        if task == \"FAQ\":\n",
    "            prompt = f\"\"\"Answer these common questions based on examples:\n",
    "            \n",
    "            Q: What is your return policy?\n",
    "            A: We accept returns within 30 days of purchase.\n",
    "            \n",
    "            Q: How do I track my order?\n",
    "            A: Use the tracking number in your confirmation email.\n",
    "            \n",
    "            Q: {user_input}\n",
    "            A: \"\"\"\n",
    "        elif task == \"Math\":\n",
    "            prompt = f\"\"\"Solve this problem step-by-step. \n",
    "            Example: \n",
    "            Problem: If Jane has 3 apples and buys 5 more, how many does she have?\n",
    "            Solution: \n",
    "            1. Start with initial apples: 3\n",
    "            2. Add purchased apples: 3 + 5 = 8\n",
    "            3. Final answer: 8\n",
    "            \n",
    "            Problem: {user_input}\n",
    "            Solution:\"\"\"\n",
    "        elif task == \"Joke\":\n",
    "            prompt = f\"\"\"Generate a joke about {user_input} formatted as JSON with setup and punchline keys.\n",
    "            \n",
    "            Example:\n",
    "            {{\n",
    "                \"setup\": \"Why did the programmer quit their job?\",\n",
    "                \"punchline\": \"Because they didn't get arrays!\"\n",
    "            }}\n",
    "            \n",
    "            New joke:\"\"\"\n",
    "        \n",
    "        payload = {\n",
    "            \"inputs\": prompt,\n",
    "            \"parameters\": {\n",
    "                \"max_new_tokens\": 200,\n",
    "                \"temperature\": 0.7,\n",
    "                \"return_full_text\": False\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        response = requests.post(API_URL, headers=headers, json=payload)\n",
    "        output = json.loads(response.content.decode(\"utf-8\"))\n",
    "        \n",
    "        if \"error\" in output:\n",
    "            return f\"Model loading error: {output['error']}\"\n",
    "            \n",
    "        return output[0]['generated_text']\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981c61f1",
   "metadata": {},
   "source": [
    "**Gradio**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebb24a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"# Multi-Task Chatbot\")\n",
    "    with gr.Row():\n",
    "        task_select = gr.Dropdown([\"FAQ\", \"Math\", \"Joke\"], label=\"Select Task\")\n",
    "        user_input = gr.Textbox(label=\"Your Input\")\n",
    "    output = gr.Textbox(label=\"Response\", interactive=False)\n",
    "    submit_btn = gr.Button(\"Ask\")\n",
    "    \n",
    "    submit_btn.click(\n",
    "        fn=generate_response,\n",
    "        inputs=[task_select, user_input],\n",
    "        outputs=output\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a9efef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    demo.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
